{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Webcam Image Recognizer </h1>\n",
    "\n",
    "<h3> Import all required libraries, define model url and directory </h3>\n",
    "Notably, we use:\n",
    "\n",
    "- OpenCV2 to pull the video feed from the webcam.\n",
    "\n",
    "- TensorFlow (and NumPy) for image classification.\n",
    "\n",
    "- GTTS to access Google Text-To-Speech API.\n",
    "\n",
    "- PyGame to reproduce the audio file pulled from GTTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "import cv2\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import os\n",
    "from threading import Thread\n",
    "\n",
    "model_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "model_dir = '/tmp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Threaded Video Processing Class </h3>\n",
    "The cv2.read() function is a blocking operation so the main thread is blocked until the frame is read from the webcam and returned. In a real time system, this slows down overall processing.\n",
    "\n",
    "  This class makes a new thread that pulls new frames from the webcam while the main thread processes the most recent frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadedVideoProcessing:\n",
    "    def __init__(self):\n",
    "        self.stream = cv2.VideoCapture(0)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "\n",
    "    def begin(self):\n",
    "        Thread(target = self.update, args = ()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.stopped:\n",
    "                return\n",
    "\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def get_curr_frame(self):\n",
    "        return self.frame\n",
    "\n",
    "    def end(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image Recognition</h3><h4>Part 1</h4>\n",
    "The Labelize class maps the class name to the result from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Labelize(object):\n",
    "    def __init__(self, class_path=None, node_path=None):\n",
    "        if not class_path:\n",
    "            class_path = os.path.join(model_dir, 'imagenet_2012_challenge_label_map_proto.pbtxt')\n",
    "        if not node_path:\n",
    "            node_path = os.path.join(model_dir, 'imagenet_synset_to_human_label_map.txt')\n",
    "        self.name_dict = self.update_dict(class_path, node_path)\n",
    "\n",
    "    def update_dict(self, class_path, node_path):\n",
    "        if not tf.gfile.Exists(class_path):\n",
    "            tf.logging.fatal('Label path does not exist: ' + str(class_path))\n",
    "        if not tf.gfile.Exists(node_path):\n",
    "            tf.logging.fatal('Node path does not exist: ' + str(node_path))\n",
    "\n",
    "        class_dict = dict()\n",
    "        for line in tf.gfile.GFile(class_path).readlines():\n",
    "            if line.startswith('  target_class:'):\n",
    "                current_class = int(line.split(': ')[1])\n",
    "            if line.startswith('  target_class_string:'):\n",
    "                class_dict[current_class] = line.split(': ')[1][1:-2]\n",
    "\n",
    "        string_dict = dict()\n",
    "        for line in tf.gfile.GFile(node_path).readlines():\n",
    "            parsed_items = re.compile(r'[n\\d]*[ \\S,]*').findall(line)\n",
    "            string_dict[parsed_items[0]] = parsed_items[2]\n",
    "\n",
    "        name_dict = dict()\n",
    "        for node, string in class_dict.items():\n",
    "            if string not in string_dict:\n",
    "                tf.logging.fatal('Label does not exist: ' + str(string))\n",
    "            name = string_dict[string]\n",
    "            name_dict[node] = name\n",
    "\n",
    "        return name_dict\n",
    "\n",
    "    def get_label(self, node):\n",
    "        if node not in self.name_dict:\n",
    "            return ''\n",
    "        return self.name_dict[node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image Recognition</h3><h4>Part 2</h4>\n",
    "First, download and extract the Google v3 CNN Inception model tar file. Next, create graph from the downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract model (if not already in model_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "filename = model_url.split('/')[-1]\n",
    "filepath = os.path.join(model_dir, filename)\n",
    "if not os.path.exists(filepath):\n",
    "    \n",
    "    def downloadbar(count, block_size, total_size):\n",
    "        sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "            (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    filepath, _ = urllib.request.urlretrieve(model_url, filepath, downloadbar)\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "tarfile.open(filepath, 'r:gz').extractall(model_dir)\n",
    "\n",
    "# Create graph to feed into TF\n",
    "with tf.gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    g_in = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The Main Loop </h3>\n",
    "\n",
    "The main loop begins with starting the video feed using the threaded video processing class. The TF sess is started and every fifth frame is saved. The frame is then fed into the model with a softmax tensor, and the result is sent to the Labelize class to generate a label. If the label is not found in the current directory, the Google text-to-speech API is used to download the tts file, which is then sent to PyGame to generate an audio description and save in the current directory. The audio description is played every 40 frames, and the label, prediction score and fps are displayed on the video feed.\n",
    "\n",
    "Hitting 'Q' quits the application and closes all windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hit 'Q' to quit.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frames = 0\n",
    "score = 0\n",
    "start_time = time.time()\n",
    "pygame.mixer.init()\n",
    "frames_since_pred = 0\n",
    "class_label = \"\"\n",
    "print(\"\\n\\nHit 'Q' to quit.\\n\\n\")\n",
    "vid = ThreadedVideoProcessing().begin()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        frame = vid.get_curr_frame()\n",
    "        frames += 1\n",
    "        if (frames % 5 == 0):\n",
    "            cv2.imwrite(\"current_frame.jpg\", frame)\n",
    "            predictions = sess.run(sess.graph.get_tensor_by_name('softmax:0'), {'DecodeJpeg/contents:0': tf.gfile.FastGFile(\"./current_frame.jpg\", 'rb').read()})\n",
    "            predictions = np.squeeze(predictions)\n",
    "            node_lookup = Labelize()\n",
    "\n",
    "            class_label = node_lookup.get_label(predictions.argsort()[-1:][::-1][0])\n",
    "            score = predictions[predictions.argsort()[-1:][::-1][0]]\n",
    "            if (class_label == \"iPod\"):\n",
    "                class_label = \"iPhone\"\n",
    "            if (score > .4):\n",
    "                labels = class_label.split()\n",
    "                class_label = \" \".join(labels[0:])\n",
    "                audio_filename = \"-\".join(labels[0])\n",
    "\n",
    "            current_time = time.time()\n",
    "            fps = frames / (current_time - start_time)\n",
    "\n",
    "        if ((frames_since_pred > 50) and (pygame.mixer.music.get_busy() == False)):\n",
    "            audio_description = audio_filename + \".mp3\"\n",
    "            if not os.path.isfile(audio_description):\n",
    "                gTTS(text=\"I see a \" + class_label, lang='en').save(audio_description)\n",
    "            frames_since_pred = 0\n",
    "            pygame.mixer.music.load(audio_description)\n",
    "            pygame.mixer.music.play()\n",
    "        if ((frames_since_pred < 40) and (frames > 10)):\n",
    "            cv2.putText(frame, class_label, (20, 400), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255))\n",
    "            cv2.putText(frame, str(np.round(score * 100, 2)) + \"%\", (20, 440), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255))\n",
    "        if (frames > 20):\n",
    "            cv2.putText(frame, \"fps: \" + str(np.round(fps, 2)), (460, 460), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255))\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        frames_since_pred += 1\n",
    "        if (cv2.waitKey(1) & 0xFF == ord(\"q\")):\n",
    "            break\n",
    "\n",
    "vid.end()\n",
    "cv2.destroyAllWindows()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
